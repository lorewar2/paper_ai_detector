from model import BertAIRegressor, ChunkedDataset, score_long_document, train
from torch.utils.data import DataLoader
from transformers import BertTokenizer

BATCH_SIZE = 16

def main():
    tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
    model = BertAIRegressor()

    # Example training data
    texts = [
        "This is a human-written academic paragraph discussing results.",
        "This text was generated by an AI model and follows predictable patterns."
    ]
    labels = [
        0.0,     # human
        100.0    # AI
    ]

    dataset = ChunkedDataset(texts, labels, tokenizer)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

    #train(model, dataloader)

    # Score a long document
    long_text = "AI Written thing, lol"
    ai_score = score_long_document(long_text, model, tokenizer)

    print(f"\nFinal AI Score: {ai_score:.2f} / 100")
    return

if __name__ == "__main__":
    main()
    